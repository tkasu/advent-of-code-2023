//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32688072
// Cuda compilation tools, release 12.1, V12.1.105
// Based on NVVM 7.0.1
//

.version 8.1
.target sm_52
.address_size 64

	// .globl	calc_dest_min
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.extern .func __assertfail
(
	.param .b64 __assertfail_param_0,
	.param .b64 __assertfail_param_1,
	.param .b32 __assertfail_param_2,
	.param .b64 __assertfail_param_3,
	.param .b64 __assertfail_param_4
)
;
.global .align 1 .b8 __unnamed_1[72] = {117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 32, 103, 101, 116, 95, 115, 101, 101, 100, 40, 99, 111, 110, 115, 116, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 32, 42, 44, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 44, 32, 117, 110, 115, 105, 103, 110, 101, 100, 32, 105, 110, 116, 41, 0};
.global .align 1 .b8 $str[23] = {69, 82, 82, 79, 82, 58, 32, 115, 101, 101, 100, 32, 110, 111, 116, 32, 102, 111, 117, 110, 100, 10, 0};
.global .align 1 .b8 $str$1[6] = {102, 97, 108, 115, 101, 0};
.global .align 1 .b8 $str$2[19] = {115, 114, 99, 47, 100, 97, 121, 53, 95, 107, 101, 114, 110, 101, 108, 46, 99, 117, 0};
.extern .shared .align 16 .b8 block_mins[];

.visible .entry calc_dest_min(
	.param .u64 calc_dest_min_param_0,
	.param .align 8 .b8 calc_dest_min_param_1[128],
	.param .u32 calc_dest_min_param_2,
	.param .u32 calc_dest_min_param_3
)
{
	.reg .pred 	%p<41>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<186>;
	.reg .b64 	%rd<47>;


	ld.param.u64 	%rd17, [calc_dest_min_param_0];
	ld.param.u32 	%r80, [calc_dest_min_param_2];
	ld.param.u32 	%r81, [calc_dest_min_param_3];
	ld.param.u32 	%r79, [calc_dest_min_param_1+120];
	ld.param.u64 	%rd25, [calc_dest_min_param_1+112];
	ld.param.u32 	%r78, [calc_dest_min_param_1+104];
	ld.param.u64 	%rd24, [calc_dest_min_param_1+96];
	ld.param.u32 	%r77, [calc_dest_min_param_1+88];
	ld.param.u64 	%rd23, [calc_dest_min_param_1+80];
	ld.param.u32 	%r76, [calc_dest_min_param_1+72];
	ld.param.u64 	%rd22, [calc_dest_min_param_1+64];
	ld.param.u32 	%r75, [calc_dest_min_param_1+56];
	ld.param.u64 	%rd21, [calc_dest_min_param_1+48];
	ld.param.u32 	%r74, [calc_dest_min_param_1+40];
	ld.param.u64 	%rd20, [calc_dest_min_param_1+32];
	ld.param.u32 	%r73, [calc_dest_min_param_1+24];
	ld.param.u64 	%rd19, [calc_dest_min_param_1+16];
	ld.param.u32 	%r72, [calc_dest_min_param_1+8];
	ld.param.u64 	%rd18, [calc_dest_min_param_1];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	setp.lt.s32 	%p1, %r80, 1;
	mov.u32 	%r175, -1;
	@%p1 bra 	$L__BB0_45;

	mad.lo.s32 	%r85, %r2, %r1, %r3;
	mul.lo.s32 	%r12, %r85, %r80;
	cvta.to.global.u64 	%rd1, %rd25;
	cvta.to.global.u64 	%rd2, %rd24;
	cvta.to.global.u64 	%rd3, %rd23;
	cvta.to.global.u64 	%rd4, %rd22;
	cvta.to.global.u64 	%rd5, %rd21;
	cvta.to.global.u64 	%rd6, %rd20;
	cvta.to.global.u64 	%rd7, %rd19;
	cvta.to.global.u64 	%rd8, %rd18;
	mov.u32 	%r156, 0;

$L__BB0_2:
	add.s32 	%r15, %r156, %r12;
	setp.ge.u32 	%p2, %r15, %r81;
	@%p2 bra 	$L__BB0_54;

	setp.eq.s32 	%p3, %r72, 0;
	@%p3 bra 	$L__BB0_8;

	mov.u32 	%r158, 0;
	mov.u32 	%r159, %r158;

$L__BB0_5:
	mul.wide.s32 	%rd26, %r158, 4;
	add.s64 	%rd9, %rd8, %rd26;
	ld.global.u32 	%r88, [%rd9+4];
	add.s32 	%r18, %r88, %r159;
	setp.gt.u32 	%p4, %r18, %r15;
	@%p4 bra 	$L__BB0_7;

	add.s32 	%r158, %r158, 2;
	setp.lt.u32 	%p5, %r158, %r72;
	mov.u32 	%r159, %r18;
	@%p5 bra 	$L__BB0_5;

$L__BB0_8:
	mov.u64 	%rd27, $str;
	cvta.global.u64 	%rd28, %rd27;
	mov.u64 	%rd29, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd28;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r92, [retval0+0];
	} // callseq 0
	mov.u64 	%rd30, $str$1;
	cvta.global.u64 	%rd31, %rd30;
	mov.u64 	%rd32, $str$2;
	cvta.global.u64 	%rd33, %rd32;
	mov.u64 	%rd34, __unnamed_1;
	cvta.global.u64 	%rd35, %rd34;
	mov.u32 	%r93, 41;
	mov.u64 	%rd36, 1;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd31;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r93;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd35;
	.param .b64 param4;
	st.param.b64 	[param4+0], %rd36;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 1
	bra.uni 	$L__BB0_9;

$L__BB0_7:
	ld.global.u32 	%r89, [%rd9];
	sub.s32 	%r90, %r15, %r159;
	add.s32 	%r164, %r90, %r89;

$L__BB0_9:
	setp.lt.s32 	%p6, %r73, 1;
	@%p6 bra 	$L__BB0_14;

	mov.u32 	%r161, 0;

$L__BB0_11:
	mul.wide.s32 	%rd37, %r161, 12;
	add.s64 	%rd10, %rd7, %rd37;
	ld.global.u32 	%r95, [%rd10];
	setp.gt.u32 	%p7, %r95, %r164;
	add.s32 	%r161, %r161, 1;
	@%p7 bra 	$L__BB0_13;
	bra.uni 	$L__BB0_12;

$L__BB0_13:
	setp.lt.s32 	%p9, %r161, %r73;
	@%p9 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_14;

$L__BB0_12:
	ld.global.u32 	%r96, [%rd10+4];
	setp.lt.u32 	%p8, %r96, %r164;
	ld.global.u32 	%r97, [%rd10+8];
	selp.b32 	%r98, 0, %r97, %p8;
	add.s32 	%r164, %r98, %r164;

$L__BB0_14:
	setp.lt.s32 	%p10, %r74, 1;
	@%p10 bra 	$L__BB0_19;

	mov.u32 	%r163, 0;

$L__BB0_16:
	mul.wide.s32 	%rd38, %r163, 12;
	add.s64 	%rd11, %rd6, %rd38;
	ld.global.u32 	%r100, [%rd11];
	setp.gt.u32 	%p11, %r100, %r164;
	add.s32 	%r163, %r163, 1;
	@%p11 bra 	$L__BB0_18;
	bra.uni 	$L__BB0_17;

$L__BB0_18:
	setp.lt.s32 	%p13, %r163, %r74;
	@%p13 bra 	$L__BB0_16;
	bra.uni 	$L__BB0_19;

$L__BB0_17:
	ld.global.u32 	%r101, [%rd11+4];
	setp.lt.u32 	%p12, %r101, %r164;
	ld.global.u32 	%r102, [%rd11+8];
	selp.b32 	%r103, 0, %r102, %p12;
	add.s32 	%r164, %r103, %r164;

$L__BB0_19:
	setp.lt.s32 	%p14, %r75, 1;
	@%p14 bra 	$L__BB0_24;

	mov.u32 	%r165, 0;

$L__BB0_21:
	mul.wide.s32 	%rd39, %r165, 12;
	add.s64 	%rd12, %rd5, %rd39;
	ld.global.u32 	%r105, [%rd12];
	setp.gt.u32 	%p15, %r105, %r164;
	add.s32 	%r165, %r165, 1;
	@%p15 bra 	$L__BB0_23;
	bra.uni 	$L__BB0_22;

$L__BB0_23:
	setp.lt.s32 	%p17, %r165, %r75;
	@%p17 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_24;

$L__BB0_22:
	ld.global.u32 	%r106, [%rd12+4];
	setp.lt.u32 	%p16, %r106, %r164;
	ld.global.u32 	%r107, [%rd12+8];
	selp.b32 	%r108, 0, %r107, %p16;
	add.s32 	%r164, %r108, %r164;

$L__BB0_24:
	setp.lt.s32 	%p18, %r76, 1;
	@%p18 bra 	$L__BB0_29;

	mov.u32 	%r167, 0;

$L__BB0_26:
	mul.wide.s32 	%rd40, %r167, 12;
	add.s64 	%rd13, %rd4, %rd40;
	ld.global.u32 	%r110, [%rd13];
	setp.gt.u32 	%p19, %r110, %r164;
	add.s32 	%r167, %r167, 1;
	@%p19 bra 	$L__BB0_28;
	bra.uni 	$L__BB0_27;

$L__BB0_28:
	setp.lt.s32 	%p21, %r167, %r76;
	@%p21 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_29;

$L__BB0_27:
	ld.global.u32 	%r111, [%rd13+4];
	setp.lt.u32 	%p20, %r111, %r164;
	ld.global.u32 	%r112, [%rd13+8];
	selp.b32 	%r113, 0, %r112, %p20;
	add.s32 	%r164, %r113, %r164;

$L__BB0_29:
	setp.lt.s32 	%p22, %r77, 1;
	@%p22 bra 	$L__BB0_34;

	mov.u32 	%r169, 0;

$L__BB0_31:
	mul.wide.s32 	%rd41, %r169, 12;
	add.s64 	%rd14, %rd3, %rd41;
	ld.global.u32 	%r115, [%rd14];
	setp.gt.u32 	%p23, %r115, %r164;
	add.s32 	%r169, %r169, 1;
	@%p23 bra 	$L__BB0_33;
	bra.uni 	$L__BB0_32;

$L__BB0_33:
	setp.lt.s32 	%p25, %r169, %r77;
	@%p25 bra 	$L__BB0_31;
	bra.uni 	$L__BB0_34;

$L__BB0_32:
	ld.global.u32 	%r116, [%rd14+4];
	setp.lt.u32 	%p24, %r116, %r164;
	ld.global.u32 	%r117, [%rd14+8];
	selp.b32 	%r118, 0, %r117, %p24;
	add.s32 	%r164, %r118, %r164;

$L__BB0_34:
	setp.lt.s32 	%p26, %r78, 1;
	@%p26 bra 	$L__BB0_39;

	mov.u32 	%r171, 0;

$L__BB0_36:
	mul.wide.s32 	%rd42, %r171, 12;
	add.s64 	%rd15, %rd2, %rd42;
	ld.global.u32 	%r120, [%rd15];
	setp.gt.u32 	%p27, %r120, %r164;
	add.s32 	%r171, %r171, 1;
	@%p27 bra 	$L__BB0_38;
	bra.uni 	$L__BB0_37;

$L__BB0_38:
	setp.lt.s32 	%p29, %r171, %r78;
	@%p29 bra 	$L__BB0_36;
	bra.uni 	$L__BB0_39;

$L__BB0_37:
	ld.global.u32 	%r121, [%rd15+4];
	setp.lt.u32 	%p28, %r121, %r164;
	ld.global.u32 	%r122, [%rd15+8];
	selp.b32 	%r123, 0, %r122, %p28;
	add.s32 	%r164, %r123, %r164;

$L__BB0_39:
	setp.lt.s32 	%p30, %r79, 1;
	@%p30 bra 	$L__BB0_44;

	mov.u32 	%r173, 0;

$L__BB0_41:
	mul.wide.s32 	%rd43, %r173, 12;
	add.s64 	%rd16, %rd1, %rd43;
	ld.global.u32 	%r125, [%rd16];
	setp.gt.u32 	%p31, %r125, %r164;
	add.s32 	%r173, %r173, 1;
	@%p31 bra 	$L__BB0_43;
	bra.uni 	$L__BB0_42;

$L__BB0_43:
	setp.lt.s32 	%p33, %r173, %r79;
	@%p33 bra 	$L__BB0_41;
	bra.uni 	$L__BB0_44;

$L__BB0_42:
	ld.global.u32 	%r126, [%rd16+4];
	setp.lt.u32 	%p32, %r126, %r164;
	ld.global.u32 	%r127, [%rd16+8];
	selp.b32 	%r128, 0, %r127, %p32;
	add.s32 	%r164, %r128, %r164;

$L__BB0_44:
	min.u32 	%r175, %r175, %r164;
	add.s32 	%r156, %r156, 1;
	setp.lt.s32 	%p34, %r156, %r80;
	@%p34 bra 	$L__BB0_2;

$L__BB0_45:
	shl.b32 	%r129, %r3, 2;
	mov.u32 	%r130, block_mins;
	add.s32 	%r131, %r130, %r129;
	st.shared.u32 	[%r131], %r175;
	bar.sync 	0;
	setp.ne.s32 	%p35, %r3, 0;
	@%p35 bra 	$L__BB0_54;

	setp.eq.s32 	%p36, %r1, 0;
	mov.u32 	%r185, -1;
	@%p36 bra 	$L__BB0_53;

	add.s32 	%r136, %r1, -1;
	mov.u32 	%r185, -1;
	and.b32  	%r184, %r1, 3;
	setp.lt.u32 	%p37, %r136, 3;
	mov.u32 	%r180, 0;
	@%p37 bra 	$L__BB0_50;

	sub.s32 	%r178, %r1, %r184;

$L__BB0_49:
	shl.b32 	%r139, %r180, 2;
	add.s32 	%r141, %r130, %r139;
	ld.shared.v4.u32 	{%r142, %r143, %r144, %r145}, [%r141];
	min.u32 	%r150, %r185, %r142;
	min.u32 	%r151, %r150, %r143;
	min.u32 	%r152, %r151, %r144;
	min.u32 	%r185, %r152, %r145;
	add.s32 	%r180, %r180, 4;
	add.s32 	%r178, %r178, -4;
	setp.ne.s32 	%p38, %r178, 0;
	@%p38 bra 	$L__BB0_49;

$L__BB0_50:
	setp.eq.s32 	%p39, %r184, 0;
	@%p39 bra 	$L__BB0_53;

	shl.b32 	%r153, %r180, 2;
	add.s32 	%r182, %r130, %r153;

$L__BB0_52:
	.pragma "nounroll";
	ld.shared.u32 	%r155, [%r182];
	min.u32 	%r185, %r185, %r155;
	add.s32 	%r182, %r182, 4;
	add.s32 	%r184, %r184, -1;
	setp.ne.s32 	%p40, %r184, 0;
	@%p40 bra 	$L__BB0_52;

$L__BB0_53:
	cvta.to.global.u64 	%rd44, %rd17;
	mul.wide.u32 	%rd45, %r2, 4;
	add.s64 	%rd46, %rd44, %rd45;
	st.global.u32 	[%rd46], %r185;

$L__BB0_54:
	ret;

}

